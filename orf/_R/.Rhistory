forest_weights_diff_up_down <- mapply(function(x,y) mapply(function(x,y) x-y, x, y,  SIMPLIFY = F), forest_weights_up, forest_weights_down, SIMPLIFY = F)
View(forest_weights_diff_up_down)
View(forest_weights_diff_up_down)
forest_weights_diff_up_down[[1]][[1]]
# compute the conditional means: 1/N(weights%*%y) (predictions are based on honest sample)
forest_cond_means <- mapply(function(x,y) lapply(x, function(x) (x%*%y)/nrow(Y_ind[[1]])), forest_weights_diff_up_down, Y_ind, SIMPLIFY = FALSE)
View(forest_cond_means)
View(forest_cond_means)
forest_multi <-      mapply(function(x,y) lapply(x, function(x) t(x)*y),                   forest_weights_diff_up_down, Y_ind, SIMPLIFY = FALSE)
View(forest_multi)
View(forest_multi)
forest_multi[[1]][[1]]
forest_multi_demeaned <- mapply(function(x,y) mapply(function(x,y) x-matrix(y, nrow = nrow(x)), x, y, SIMPLIFY = FALSE), forest_multi, forest_cond_means, SIMPLIFY = F)
forest_multi_demeaned
forest_multi_demeaned <- mapply(function(x,y) mapply(function(x,y) x-matrix(y, nrow = nrow(x)), x, y, SIMPLIFY = FALSE), forest_multi, forest_cond_means, SIMPLIFY = F)
forest_multi_demeaned
View(forest_multi_demeaned)
View(forest_multi_demeaned)
forest_multi_demeaned[[1]][[1]]
forest_multi_demeaned_sq_sum_norm <- lapply(forest_multi_demeaned, function(x) lapply(x, function(x) (sum(x^2))*(nrow(Y_ind[[1]])/(nrow(Y_ind[[1]])-1))))
View(forest_multi_demeaned_sq_sum_norm)
View(forest_multi_demeaned_sq_sum_norm)
forest_multi_demeaned_sq_sum_norm[[1]][[1]]
forest_multi_demeaned_0_last <- append(forest_multi_demeaned, list(rep(list(matrix(0, ncol = ncol(forest_multi_demeaned[[1]][[1]]), nrow = nrow(forest_multi_demeaned[[1]][[1]]))), ncol(X_eval)))) # append zero matrix list
View(forest_multi_demeaned_0_last)
View(forest_multi_demeaned_0_last)
View(forest_multi_demeaned)
View(forest_multi_demeaned)
View(forest_multi_demeaned_sq_sum_norm)
View(forest_multi_demeaned_sq_sum_norm)
View(forest_multi_demeaned_0_last)
View(forest_multi_demeaned_0_last)
forest_multi_demeaned_0_first <- append(list(rep(list(matrix(0, ncol = ncol(forest_multi_demeaned[[1]][[1]]), nrow = nrow(forest_multi_demeaned[[1]][[1]]))), ncol(X_eval))), forest_multi_demeaned) # prepend zero matrix list
View(forest_multi_demeaned_0_first)
View(forest_multi_demeaned_0_first)
# compute the multiplication of category m with m-1 according to the covariance formula (sum, normalize and multiply by 2)
forest_multi_demeaned_cov_sum_norm_mult2 <- mapply(function(x,y) mapply(function(x,y) (sum(x*y))*(nrow(Y_ind[[1]])/(nrow(Y_ind[[1]])-1))*2, x, y, SIMPLIFY = FALSE), forest_multi_demeaned_0_first, forest_multi_demeaned_0_last, SIMPLIFY = F)
View(forest_multi_demeaned_cov_sum_norm_mult2)
View(forest_multi_demeaned_cov_sum_norm_mult2)
scaling_factor_squared <- lapply(scaling_factor, function(x) (mean(x))^2)
View(scaling_factor_squared)
View(scaling_factor_squared)
scaling_factor_squared[[1]]
scaling_factor_squared[[2]]
scaling_factor_squared[[3]]
scaling_factor_squared[[4]]
variance <- lapply(forest_multi_demeaned_sq_sum_norm, function(x) mapply(function(x,y) x/y, x, scaling_factor_squared, SIMPLIFY = FALSE) )
View(variance)
View(variance)
covariance <- lapply(forest_multi_demeaned_cov_sum_norm_mult2, function(x) mapply(function(x,y) x/y, x, scaling_factor_squared, SIMPLIFY = FALSE) )
View(covariance)
View(covariance)
variance_last <- append(variance, list(rep(list(rep(0, length(variance[[1]][[1]]))), X_cols))) # append zero element list
variance_first <- append(list(rep(list(rep(0, length(variance[[1]][[1]]))), X_cols)), variance) # prepend zero element list
View(variance_last)
View(variance_last)
View(variance_first)
View(variance_first)
View(variance_first)
variance_me <- mapply(function(x,y,z) mapply(function(x,y,z) (x+y-z), x, y, z, SIMPLIFY = FALSE), variance_last, variance_first, covariance, SIMPLIFY = F)
View(variance_me)
View(variance_me)
variance_me <- mapply(function(x,y,z) mapply(function(x,y,z) (x+y-z), x, y, z, SIMPLIFY = FALSE), variance_last, variance_first, covariance, SIMPLIFY = F)
variance_me <- sapply(variance_me, function(x) sapply(x, function(x) as.matrix(x)))
View(variance_me)
View(variance_me)
variance_me <- mapply(function(x,y,z) mapply(function(x,y,z) (x+y-z), x, y, z, SIMPLIFY = FALSE), variance_last, variance_first, covariance, SIMPLIFY = F)
View(variance_me)
View(variance_me)
variance_me <- sapply(variance_me, function(x) sapply(x, function(x) as.matrix(x)))
View(variance_me)
View(variance_me)
sd_me <- sqrt(variance_me)
sd_me
## standard deviations
# take square root of variance
sd_me <- sqrt(variance_me)
# t values and p values
t_value <- (marginal_effects)/(sd_me)
# control for dividing zero by zero
t_value[is.nan(t_value)] = 0
# p values
p_values <- 2*pnorm(-abs(t_value))
p_values
t_value
# save forest information
forest_info <- list(inputs, categories, eval, window, newdata, inference)
names(forest_info) <- c("inputs", "categories", "eval", "window", "newData", "marginsInference")
# put everything into a list of results
results <- list(forest_info, marginal_effects, variance_me, sd_me, t_value, p_values)
names(results) <- c("info", "effects", "variances", "errors", "tvalues", "pvalues")
class(results) <- "margins.orf"
return(results)
set.seed(1)
n.obs  <- 1000
n.vars <- 50
x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
View(x)
xbetat   <- 0.5 + 0.25 * x[,21] - 0.25 * x[,41]
x[,21]
x[,21]
xbetat   <- 0.5 + 0.25 * x[,21] - 0.25 * x[,41]
trt.prob <- exp(xbetat) / (1 + exp(xbetat))
trt      <- rbinom(n.obs, 1, prob = trt.prob)
# simulate delta
delta <- (0.5 + x[,2] - 0.5 * x[,3] - 1 * x[,11] + 1 * x[,1] * x[,12] )
rnorm(n.obs)
drop(xbeta)
# simulate main effects g(X)
xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
xbeta <- xbeta + delta * (2 * trt - 1)
drop(xbeta)
?drop
## Ordered Forest
require(orf)
# load example data
data(odata)
# specify response and covariates
Y <- as.numeric(odata[, 1])
X <- as.matrix(odata[, -1])
# Run simplest version of ORF (bootstrapping TRUE & honesty FALSE)
orf_fit <- orf(X, Y, num.trees = 1000, mtry = 2, min.node.size = 5,
replace = TRUE, honesty = FALSE,
inference = FALSE, importance = FALSE)
# Get OBB predictions
head(orf_fit$predictions)
# Get in-sample predictions
pred <- predict(orf_fit, newdata = X, type = "probs", inference = FALSE)
head(pred$predictions)
# estimate marginal effects
mm = margins(orf_fit, newdata = NULL, eval = "mean", window = 0.1, inference = FALSE)
margins(orf_fit)
plot(orf_fit)
predict(orf_fit)
print(orf_fit)
print(orf_fit)
print(mm)
print(pred)
summary(orf_fit)
print(orf_fit)
summary(mm)
print(mm)
summary(pred)
print(pred)
print(orf_fit)
orf_fit
summary(orf_fit)
## Ordered Forest
require(orf)
# load example data
data(odata)
# specify response and covariates
Y <- as.numeric(odata[, 1])
X <- as.matrix(odata[, -1])
# Run simplest version of ORF (bootstrapping TRUE & honesty FALSE)
orf_fit <- orf(X, Y, num.trees = 1000, mtry = 2, min.node.size = 5,
replace = TRUE, honesty = FALSE,
inference = FALSE, importance = FALSE)
# Get OBB predictions
head(orf_fit$predictions)
# Get in-sample predictions
pred <- predict(orf_fit, newdata = X, type = "probs", inference = FALSE)
head(pred$predictions)
# estimate marginal effects
mm = margins(orf_fit, newdata = NULL, eval = "mean", window = 0.1, inference = FALSE)
# Run HONEST version of ORF (bootstrapping FALSE & honesty TRUE)
orf_hon <- orf(X, Y, num.trees = 1000, mtry = 2, min.node.size = 5,
replace = FALSE, honesty = TRUE,
inference = FALSE, importance = FALSE)
# Get OBB predictions
head(orf_hon$predictions)
summary(orf_hon)
# Run HONEST version of ORF (bootstrapping FALSE & honesty TRUE)
orf_hon <- orf(X, Y, num.trees = 1000, mtry = 2, min.node.size = 5,
replace = TRUE, honesty = TRUE,
inference = FALSE, importance = FALSE)
# Get OBB predictions
summary(orf_hon)
# Run HONEST version of ORF (bootstrapping FALSE & honesty TRUE)
orf_hon <- orf(X, Y, num.trees = 1000, mtry = 2, min.node.size = 5,
replace = FALSE, honesty = TRUE,
inference = FALSE, importance = FALSE)
summary(orf_hon)
################################################################################
###         R vs. Python Comparison of the Ordered Forest Estimation         ###
################################################################################
# set the directory to the one of the source file (requires Rstudio)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
path <- getwd()
# load packages
library(orf)
library(ggplot2)
library(tidyverse)
library(stevedata)
# ---------------------------------------------------------------------------- #
# Empirical Data
# load data on health outcome from stevedata package
data("mm_nhis", package = "stevedata")
dataset <- mm_nhis
# subset the data only with the desired varlist as in mastering metrics example
varlist <- c("hi", "hlth", "nwhite", "age", "yedu", "famsize", "empl", "inc", "fml")
dataset <- dataset[, varlist]
# outcome
dataset$y <- dataset$hlth
# remove original variable
dataset$hlth <- NULL
# remove NAs
dataset <- dataset[complete.cases(dataset), ]
dataset <- as.data.frame(dataset)
# rename vars nicely
colnames(dataset) <- c("HealthInsurance", "NonWhite", "Age", "Education",
"FamilySize", "Employed", "Income", "Female", "y")
# save data to disk
write.csv(dataset, file = paste0(path, '/data/empdata_test.csv'), row.names = F)
# ---------------------------------------------------------------------------- #
# Synthetic Data
# generate example data using the DGP from orf package data
set.seed(123) # set seed for replicability
# number of observations (at least 10k for reliable comparison)
n  <- 10000
# various covariates
X1 <- rnorm(n, 0, 1)    # continuous
X2 <- rbinom(n, 2, 0.5) # categorical
X3 <- rbinom(n, 1, 0.5) # dummy
X4 <- rnorm(n, 0, 10)   # noise
# bind into matrix
X <- as.matrix(cbind(X1, X2, X3, X4))
# deterministic component
deterministic <- X1 + X2 + X3
# generate continuous outcome with logistic error
Y <- deterministic + rlogis(n, 0, 1)
# thresholds for continuous outcome
cuts <- quantile(Y, c(0, 1/3, 2/3, 1))
# discretize outcome into ordered classes 1, 2, 3
Y <- as.numeric(cut(Y, breaks = cuts, include.lowest = TRUE))
# save data as a dataframe
odata <- as.data.frame(cbind(Y, X))
# save data to disk
write.csv(odata, file = paste0(path, '/data/odata_test.csv'), row.names = F)
# ---------------------------------------------------------------------------- #
# Benchmark settings:
replace_options <- list(FALSE, TRUE)
honesty_options <- list(FALSE, TRUE)
inference_options <- list(FALSE, TRUE)
data_types <- list('synth', 'emp')
# start benchmarks
for (data_idx in data_types) {
# based on data type, determine X and Y
if (data_idx == 'synth') {
# specify response and covariates
Y <- as.numeric(odata[, 1])
X <- as.matrix(odata[, -1])
} else {
# specify response and covariates
X <- as.matrix(dataset[, 1:ncol(dataset)-1])
Y <- as.numeric(dataset[, ncol(dataset)])
}
# loop through different settings and save the results
for (inference_idx in inference_options) {
# loop through honesty options
for (honesty_idx in honesty_options) {
# check if the setting is admissible
if (inference_idx == TRUE & honesty_idx == FALSE) {
next
}
# lastly loop through subsampling option
for (replace_idx in replace_options) {
# check if the setting is admissible (for comparison with python)
if (honesty_idx == TRUE & replace_idx == TRUE) {
next
}
# print current iteration
print(paste('data:', data_idx,
'inference:', inference_idx,
'honesty:',honesty_idx,
'replace:', replace_idx, sep = " "))
# set seed for replicability
set.seed(123)
# fit orf (at least 2000 trees for reliable comparison)
orf_fit <- orf(X, Y, num.trees = 2000, min.node.size = 5, mtry = 0.3,
replace = replace_idx,
honesty = honesty_idx,
inference = inference_idx)
# get in-sample results
orf_pred <- orf_fit$predictions
orf_var <- orf_fit$variances
orf_rps <- orf_fit$accuracy$RPS
orf_mse <- orf_fit$accuracy$MSE
# wrap into list
fit_results <- list(orf_pred, orf_var, orf_rps, orf_mse)
names(fit_results) <- c('orf_pred', 'orf_var', 'orf_rps', 'orf_mse')
# get the plot
orf_plot <- plot(orf_fit)
# get the results for margins (mean margins for reliable comparison)
orf_margins <- margins(orf_fit, eval = 'mean')
margins_effects <- orf_margins$effects
margins_vars <- orf_margins$variances
# wrap into list
margins_results <- list(margins_effects, margins_vars)
names(margins_results) <- c('margins_effects', 'margins_vars')
# save the results for plot
ggsave(filename = paste0('/results/R_', data_idx, '_', 'plot_I_', inference_idx,
'_H_', honesty_idx, '_R_', replace_idx, '.png'),
plot = orf_plot, path = path)
# save the results for fit
for (fit_idx in seq_along(fit_results)) {
# check if its empty
if (is.null(fit_results[[fit_idx]])) {
next
}
# save the results
write.csv(fit_results[[fit_idx]],
file = paste0(path, '/results/R_', data_idx, '_',
names(fit_results)[[fit_idx]],
'_I_', inference_idx, '_H_', honesty_idx, '_R_',
replace_idx, '.csv'),
row.names = FALSE)
}
# save the results for margins
for (margin_idx in seq_along(margins_results)) {
# check if its empty
if (is.null(margins_results[[margin_idx]])) {
next
}
# save the results
write.csv(margins_results[[margin_idx]],
file = paste0(path, '/results/R_', data_idx, '_',
names(margins_results)[[margin_idx]],
'_I_', inference_idx, '_H_', honesty_idx, '_R_',
replace_idx, '.csv'),
row.names = FALSE)
}
}
}
}
}
################################################################################
###         R vs. Python Comparison of the Ordered Forest Estimation         ###
################################################################################
# set the directory to the one of the source file (requires Rstudio)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
path <- getwd()
# load packages
library(orf)
library(ggplot2)
library(tidyverse)
library(stevedata)
library(ggplot2)
# ---------------------------------------------------------------------------- #
# Empirical Data
# load data on health outcome from stevedata package
data("mm_nhis", package = "stevedata")
dataset <- mm_nhis
# subset the data only with the desired varlist as in mastering metrics example
varlist <- c("hi", "hlth", "nwhite", "age", "yedu", "famsize", "empl", "inc", "fml")
dataset <- dataset[, varlist]
# outcome
dataset$y <- dataset$hlth
# remove original variable
dataset$hlth <- NULL
# remove NAs
dataset <- dataset[complete.cases(dataset), ]
dataset <- as.data.frame(dataset)
# rename vars nicely
colnames(dataset) <- c("HealthInsurance", "NonWhite", "Age", "Education",
"FamilySize", "Employed", "Income", "Female", "y")
# save data to disk
write.csv(dataset, file = paste0(path, '/data/empdata_test.csv'), row.names = F)
# ---------------------------------------------------------------------------- #
# Synthetic Data
# generate example data using the DGP from orf package data
set.seed(123) # set seed for replicability
# number of observations (at least 10k for reliable comparison)
n  <- 10000
# various covariates
X1 <- rnorm(n, 0, 1)    # continuous
X2 <- rbinom(n, 2, 0.5) # categorical
X3 <- rbinom(n, 1, 0.5) # dummy
X4 <- rnorm(n, 0, 10)   # noise
# bind into matrix
X <- as.matrix(cbind(X1, X2, X3, X4))
# deterministic component
deterministic <- X1 + X2 + X3
# generate continuous outcome with logistic error
Y <- deterministic + rlogis(n, 0, 1)
# thresholds for continuous outcome
cuts <- quantile(Y, c(0, 1/3, 2/3, 1))
# discretize outcome into ordered classes 1, 2, 3
Y <- as.numeric(cut(Y, breaks = cuts, include.lowest = TRUE))
# save data as a dataframe
odata <- as.data.frame(cbind(Y, X))
# save data to disk
write.csv(odata, file = paste0(path, '/data/odata_test.csv'), row.names = F)
# ---------------------------------------------------------------------------- #
# Benchmark settings:
replace_options <- list(FALSE, TRUE)
honesty_options <- list(FALSE, TRUE)
inference_options <- list(FALSE, TRUE)
data_types <- list('synth', 'emp')
# start benchmarks
for (data_idx in data_types) {
# based on data type, determine X and Y
if (data_idx == 'synth') {
# specify response and covariates
Y <- as.numeric(odata[, 1])
X <- as.matrix(odata[, -1])
} else {
# specify response and covariates
X <- as.matrix(dataset[, 1:ncol(dataset)-1])
Y <- as.numeric(dataset[, ncol(dataset)])
}
# loop through different settings and save the results
for (inference_idx in inference_options) {
# loop through honesty options
for (honesty_idx in honesty_options) {
# check if the setting is admissible
if (inference_idx == TRUE & honesty_idx == FALSE) {
next
}
# lastly loop through subsampling option
for (replace_idx in replace_options) {
# check if the setting is admissible (for comparison with python)
if (honesty_idx == TRUE & replace_idx == TRUE) {
next
}
# print current iteration
print(paste('data:', data_idx,
'inference:', inference_idx,
'honesty:',honesty_idx,
'replace:', replace_idx, sep = " "))
# set seed for replicability
set.seed(123)
# fit orf (at least 2000 trees for reliable comparison)
orf_fit <- orf(X, Y, num.trees = 2000, min.node.size = 5, mtry = 0.3,
replace = replace_idx,
honesty = honesty_idx,
inference = inference_idx)
# get in-sample results
orf_pred <- orf_fit$predictions
orf_var <- orf_fit$variances
orf_rps <- orf_fit$accuracy$RPS
orf_mse <- orf_fit$accuracy$MSE
# wrap into list
fit_results <- list(orf_pred, orf_var, orf_rps, orf_mse)
names(fit_results) <- c('orf_pred', 'orf_var', 'orf_rps', 'orf_mse')
# get the plot
orf_plot <- plot(orf_fit)
# get the results for margins (mean margins for reliable comparison)
orf_margins <- margins(orf_fit, eval = 'mean')
margins_effects <- orf_margins$effects
margins_vars <- orf_margins$variances
# wrap into list
margins_results <- list(margins_effects, margins_vars)
names(margins_results) <- c('margins_effects', 'margins_vars')
# save the results for plot
ggsave(filename = paste0('/results/R_', data_idx, '_', 'plot_I_', inference_idx,
'_H_', honesty_idx, '_R_', replace_idx, '.png'),
plot = orf_plot, path = path)
# save the results for fit
for (fit_idx in seq_along(fit_results)) {
# check if its empty
if (is.null(fit_results[[fit_idx]])) {
next
}
# save the results
write.csv(fit_results[[fit_idx]],
file = paste0(path, '/results/R_', data_idx, '_',
names(fit_results)[[fit_idx]],
'_I_', inference_idx, '_H_', honesty_idx, '_R_',
replace_idx, '.csv'),
row.names = FALSE)
}
# save the results for margins
for (margin_idx in seq_along(margins_results)) {
# check if its empty
if (is.null(margins_results[[margin_idx]])) {
next
}
# save the results
write.csv(margins_results[[margin_idx]],
file = paste0(path, '/results/R_', data_idx, '_',
names(margins_results)[[margin_idx]],
'_I_', inference_idx, '_H_', honesty_idx, '_R_',
replace_idx, '.csv'),
row.names = FALSE)
}
}
}
}
}
# ---------------------------------------------------------------------------- #
ggsave(filename = paste0('/results/R_', data_idx, '_', 'plot_I_', inference_idx,
'_H_', honesty_idx, '_R_', replace_idx, '.png'),
plot = orf_plot, path = path)
paste0('/results/R_', data_idx, '_', 'plot_I_', inference_idx,
'_H_', honesty_idx, '_R_', replace_idx, '.png')
library(ggplot2)
library(orf)
# load packages
library(ggplot2)
library(orf)
library(ggplot2)
library(tidyverse)
library(stevedata)
library(orf)
library(ggplot2)
library(tidyverse)
library(stevedata)
# load packages
library(ggplot2)
library(tidyverse)
library(stevedata)
